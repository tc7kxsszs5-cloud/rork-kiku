# Политика контента kiku (Content Policy)

## Введение

Данная политика определяет правила модерации контента в приложении kiku. Цель — защитить детей от вредного контента, при этом уважая приватность и не создавая излишней цензуры.

**Применимость:** Все сообщения (текст, изображения, аудио), обрабатываемые AI-системой kiku

**Версия:** 1.0 (черновик)  
**Дата:** 2026-01-02  
**Статус:** Требуется юридическая проверка и утверждение

⚠️ **ВАЖНО:** Эта политика — черновик для internal use и обсуждения. Финальная версия должна быть проверена юристами, специализирующимися на child safety, COPPA/GDPR-K compliance, и content moderation.

---

## Категории запрещённого контента

### 1. Сексуальный контент и эксплуатация детей

**Строгий запрет (нулевая толерантность):**

- **CSAM (Child Sexual Abuse Material)** — любые изображения, видео, описания сексуального характера с участием детей
  - **Действие:** Немедленная блокировка контента, заморозка аккаунта отправителя, уведомление правоохранительных органов (согласно закону)
  - **Escalation:** Автоматический report в NCMEC (National Center for Missing & Exploited Children, для US) или аналогичные организации в других юрисдикциях

- **Груминг (Child Grooming)** — попытки установить доверительные отношения с ребёнком с целью сексуальной эксплуатации
  - Примеры: просьба о личных фото, предложение встретиться тайно от родителей, обсуждение сексуальных тем
  - **Действие:** Высокий риск алерт для родителей, блокировка контакта (по запросу родителя), возможна заморозка аккаунта отправителя

- **Сексуализированный контент** — неприемлемые комментарии/изображения сексуального характера в общении с детьми
  - Примеры: nude/semi-nude фото, сексуальные намёки, обсуждение порнографии
  - **Действие:** Критический риск алерт, родитель решает дальнейшие шаги

### 2. Насилие и угрозы

**Запрещено:**

- **Прямые угрозы физического насилия**
  - Примеры: "Я тебя убью", "Я тебя побью", угрозы с оружием
  - **Действие:** Критический риск алерт, возможно уведомление правоохранительных органов (если угроза реальная)

- **Изображения насилия**
  - Примеры: кровь, раны, драки, изображения оружия в угрожающем контексте
  - **Действие:** Высокий риск алерт, блокировка изображения (размытие/hide)

- **Призывы к насилию**
  - Примеры: "Давай побьём [имя]", организация групповых нападений
  - **Действие:** Высокий риск алерт

- **Self-harm и суицидальные мысли**
  - Примеры: "Хочу покончить с собой", изображения порезов, обсуждение способов самоубийства
  - **Действие:** Критический риск алерт + рекомендации ресурсов помощи (телефон доверия, психологи)

### 3. Буллинг и harassment

**Запрещено:**

- **Оскорбления и насмешки**
  - Примеры: "Ты тупой", "Ты уродливый", "Никто тебя не любит"
  - **Действие:** Средний-высокий риск алерт (зависит от контекста и частоты)

- **Групповой буллинг**
  - Примеры: несколько человек одновременно оскорбляют одного ребёнка
  - **Действие:** Высокий риск алерт

- **Доксинг (Doxxing)**
  - Публикация личной информации ребёнка без согласия (адрес, телефон, школа)
  - **Действие:** Критический риск алерт, немедленное удаление контента

- **Кибербуллинг на основе identity**
  - Дискриминация по расе, религии, полу, сексуальной ориентации, инвалидности
  - Примеры: расистские оскорбления, homophobic slurs
  - **Действие:** Высокий риск алерт

### 4. Мошенничество и exploitation

**Запрещено:**

- **Запрос личной информации**
  - Примеры: "Скажи мне свой адрес", "Какой у тебя пароль от аккаунта", "Дай мне номер телефона родителей"
  - **Действие:** Высокий риск алерт

- **Финансовое мошенничество**
  - Примеры: просьба о деньгах, предложение "быстрого заработка", фишинг
  - **Действие:** Высокий риск алерт

- **Шантаж**
  - Примеры: "Если не сделаешь [X], я расскажу всем [Y]", угроза публикации личных фото/информации
  - **Действие:** Критический риск алерт

### 5. Наркотики, алкоголь, табак

**Контекстно запрещено:**

- **Предложение наркотиков/алкоголя/табака детям**
  - Примеры: "Хочешь попробовать?", "Принеси из дома алкоголь"
  - **Действие:** Высокий риск алерт

- **Обсуждение употребления** (контекстно)
  - Если ребёнок рассказывает о том, что пробовал — это не запрещено, но родителя нужно уведомить
  - **Действие:** Средний риск алерт (informational для родителя)

- **Изображения с наркотиками/алкоголем**
  - **Действие:** Средний-высокий риск алерт

### 6. Нелегальная деятельность

**Запрещено:**

- **Обсуждение/планирование illegal activities**
  - Примеры: кража, взлом, вандализм, прогулы школы (в контексте нарушения)
  - **Действие:** Средний-высокий риск алерт (зависит от серьёзности)

- **Продажа нелегальных товаров/услуг**
  - **Действие:** Высокий риск алерт

---

## Уровни фильтрации (Moderation Levels)

Родители могут выбрать один из трёх уровней чувствительности фильтрации:

### Уровень 1: Жёсткая фильтрация (Strict)

**Рекомендовано для:** Дети младше 10 лет

**Блокируется:**
- Все категории 1-6 (выше)
- Даже mild оскорбления (например, "дурак", "идиот")
- Любые упоминания романтических отношений (если контекст неприемлемый)
- Любое ненормативное слово

**Threshold для алертов:**
- Low risk → Alert родителю
- Medium+ risk → Alert + блокировка

**False positives:** Выше (могут блокироваться безобидные сообщения), но это trade-off для максимальной безопасности

### Уровень 2: Умеренная фильтрация (Moderate) — Рекомендовано по умолчанию

**Рекомендовано для:** Дети 10-14 лет

**Блокируется:**
- Все категории 1-6, но с контекстным анализом
- Оскорбления блокируются, если они повторяющиеся или серьёзные
- Ненормативная лексика → средний риск алерт (не автоблокировка)

**Threshold для алертов:**
- Low risk → Logged, но не alert (родитель может просмотреть в статистике)
- Medium risk → Alert родителю
- High+ risk → Alert + рекомендация блокировки

**Balance:** Меньше false positives, но всё ещё высокая защита

### Уровень 3: Мягкая фильтрация (Lenient)

**Рекомендовано для:** Подростки 14-16 лет (большая автономия)

**Блокируется:**
- Только критичные категории (CSAM, груминг, прямые угрозы, суицидальные мысли)
- Буллинг и оскорбления → алерт, но не автоблокировка (родитель сам решает)

**Threshold для алертов:**
- Low/Medium risk → Logged, родитель может просмотреть при желании
- High/Critical risk → Alert

**Цель:** Дать подростку больше приватности, но всё ещё защищать от серьёзных угроз

---

## Правила эскалации (Escalation Workflow)

### Автоматическая обработка (AI)

1. **Сообщение отправляется** → AI анализирует (текст/изображение/аудио)
2. **Risk score присваивается** (0-4: safe, low, medium, high, critical)
3. **Действие на основе риска:**
   - **Safe (0):** Нет действий
   - **Low (1):** Логируется, родитель может просмотреть в статистике (если включено)
   - **Medium (2):** Alert родителю (push notification + email)
   - **High (3):** Alert + рекомендация действия (заблокировать контакт, поговорить с ребёнком)
   - **Critical (4):** Немедленный alert + автоблокировка (опционально) + эскалация на ручную модерацию

### Ручная модерация (Human Review)

**Когда триггерится:**
- Critical risk cases (для double-check)
- Спорные случаи (AI не уверен → confidence score < 70%)
- Appeals от родителей/детей ("This is false positive")

**Процесс:**
1. **Модератор получает queue** спорных сообщений
2. **Просмотр контента** + AI analysis explanation
3. **Принятие решения:**
   - Подтвердить AI (это действительно опасно)
   - Переопределить (false positive, безопасно)
   - Эскалировать далее (очень серьёзный case → senior moderator или legal team)
4. **Feedback в ML систему** → используется для re-training моделей

**SLA (Service Level Agreement) для ручной модерации:**
- Critical cases: < 1 час response time
- High risk cases: < 4 часа
- Medium risk appeals: < 24 часа

### Заморозка аккаунта (Account Suspension)

**Когда применяется:**
- Отправитель (не ребёнок, а внешний контакт) систематически отправляет опасный контент
- CSAM или grooming detected
- Повторные нарушения после warnings

**Процесс:**
1. **Automatic temp ban** (24-48 часов) после critical risk detection
2. **Manual review** модератором
3. **Permanent ban** если подтверждено нарушение (с уведомлением правоохранительных органов, если требуется)

**Appeals процесс:**
- Забаненный пользователь может подать appeal
- Review в течение 7 дней
- Final decision от senior moderation team

---

## Подход к «здоровым родителям» и верификации

### Проблема: Кто мониторит родителей?

kiku предназначен для защиты детей от внешних угроз, но что если сам родитель представляет угрозу? (Например, абъюзивный родитель использует kiku для тотального контроля над ребёнком)

### Меры для предотвращения abuse:

**1. Верификация родителей**

**Варианты верификации (от простых к сложным):**

- **Email/SMS верификация** (минимальный уровень)
  - Подтверждение, что это реальный человек, а не bot

- **Документальная проверка (Document Verification)**
  - Родитель загружает документ (паспорт, водительское удостоверение)
  - AI/human verification для подтверждения identity
  - **Плюсы:** Подтверждает, что это взрослый
  - **Минусы:** Не подтверждает, что это здоровый родитель

- **Банковская верификация (Bank Verification)**
  - Связывание банковской карты (microdeposits или плата $1)
  - **Плюсы:** Трудно создать fake аккаунты (требуется реальная карта)
  - **Минусы:** Barrier to entry (не все родители хотят давать банковские данные)

- **Социальные проверки (Social Verification)**
  - Recommendation от других verified parents (trust network)
  - LinkedIn/Facebook verification (подтверждение реальности аккаунта)
  - **Плюсы:** Community-driven trust
  - **Минусы:** Медленно, не масштабируется

**Рекомендация для MVP:** Email + optional документальная проверка

**Для будущего:** Комбинация методов + scoring system (больше проверок → выше trust score)

**2. Transparency для детей**

- Дети **должны знать**, что родители мониторят их чаты
- kiku показывает уведомление ребёнку: "Ваши чаты защищены приложением kiku. Родители получают уведомления о небезопасном контенте."
- **Никакого скрытого мониторинга** — это unethical и может нарушить trust

**3. Ограничения для родителей**

- Родители **НЕ видят все сообщения** ребёнка (это нарушение приватности)
- Родители получают **только алерты о потенциально опасном контенте**
- Опция для подростков (14+): "Do not show parent low/medium risks" (только critical)

**4. Abuse detection**

**Red flags (что может указывать на абъюзивного родителя):**
- Родитель **постоянно** проверяет все сообщения (obsessive monitoring)
- Родитель блокирует **все** контакты ребёнка (isolation)
- Ребёнок пытается удалить приложение или выражает distress

**Действия:**
- Внутренний monitoring patterns
- Если detected abuse patterns → рекомендации ресурсов (child welfare organizations)
- **Delicat issue:** kiku не может автоматически репортить родителей (legal/ethical implications), но можем предоставить ресурсы

**5. Educational content для родителей**

- В приложении: советы по здоровому мониторингу
- "Как говорить с ребёнком о безопасности без нарушения trust"
- "Баланс между контролем и автономией"

**6. Child advocacy partnerships**

- Partnership с child welfare organizations
- Hotline для детей, которые чувствуют, что родители злоупотребляют мониторингом

---

## Исключения и edge cases

### 1. Educational content

**Примеры:**
- Обсуждение в школьном проекте о войне (может содержать изображения насилия)
- Biology класс обсуждает human body (может быть flag как сексуальный контент)

**Решение:**
- Контекстный анализ AI (если это школьный чат, снизить threshold)
- Родитель может mark as "educational" (false positive)

### 2. Peer-to-peer playful banter

**Примеры:**
- Друзья шутят друг над другом ("Ты дурак!" в контексте игры)

**Решение:**
- AI учитывает тон и контекст
- Если relationship между детьми positive (длительная дружба), снизить risk score

### 3. Child reporting own issues

**Примеры:**
- Ребёнок пишет другу: "Меня бьют дома"

**Решение:**
- Это критичный case, но не от external threat
- Alert родителю (если родитель не abuser) или child welfare resources

---

## Compliance и legal review

⚠️ **ВАЖНО:** Эта политика должна быть проверена юристами в следующих областях:

### 1. Child protection laws
- **COPPA (US)**: Требования к parental consent и data handling
- **GDPR-K (EU)**: Требования к обработке данных детей
- **ФЗ-152 (Russia)**: Персональные данные детей

### 2. Content moderation laws
- **Section 230 (US)**: Immunity для platforms от user-generated content (но kiku активно модерирует, поэтому нужен анализ)
- **DSA (EU Digital Services Act)**: Требования к content moderation и transparency

### 3. Mandatory reporting laws
- **Когда kiku обязан репортить в правоохранительные органы?**
  - CSAM: обязательно (во всех юрисдикциях)
  - Child abuse: зависит от юрисдикции
  - Imminent threats: обязательно

### 4. Liability
- **Может ли kiku быть liable, если пропустили опасный контент?**
- **Disclaimer:** kiku is a tool to assist parents, не замена для родительского надзора

---

## Мониторинг и улучшение политики

### Quarterly Review

- Каждые 3 месяца: review effectiveness политики
- Метрики:
  - False positive rate
  - False negative rate (если известны real cases, которые мы пропустили)
  - Parent satisfaction (survey)
  - Moderator feedback

### Community Feedback

- Родители и эксперты могут предлагать изменения в политику
- Transparency: публикация changelog политики

### Advisory Board

- Child psychologists
- Legal experts (COPPA/GDPR)
- Content moderation experts
- Survivors of online abuse (consultants)

---

## Примечания для финальной версии

**Что нужно добавить:**
- [ ] Конкретные примеры для каждой категории (с screenshots/mockups)
- [ ] Юридическая review и approval
- [ ] Localization (адаптация для разных культур и юрисдикций)
- [ ] Training materials для модераторов
- [ ] Public-facing version (упрощённая для родителей/детей)

**Контакты для review:**
- Legal counsel: [PLACEHOLDER]
- Child safety expert: [PLACEHOLDER]
- Content moderation expert: [PLACEHOLDER]

---

**Дата создания:** 2026-01-02  
**Версия:** 1.0 (черновик)  
**Автор:** kiku Policy Team  
**Статус:** Draft — требуется ОБЯЗАТЕЛЬНАЯ legal review перед использованием
